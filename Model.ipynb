{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-qhr2sdoBvRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675469fa-467a-4130-c1a4-d5d8c84bc16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Import important lib.\n",
        "import nltk\n",
        "#!pip install gradio\n",
        "#!pip install transformers\n",
        "import librosa\n",
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
        "nltk.download(\"punkt\")\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the pre-trained model and the tokenizer\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYxEyMSHDZVF",
        "outputId": "c8c06feb-55a7-4bab-da9e-3b6210315cfe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:792: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#reading the file\n",
        "speech, sample_rate = librosa.load('/content/sales_call_telephone_marketers.wav')\n",
        "#make it 1-D\n",
        "if len(speech.shape) > 1:\n",
        "    speech = speech[:,0] + speech[:,1]\n",
        "#Resampling the audio at 16KHz\n",
        "if sample_rate !=16000:\n",
        "  speech = librosa.resample(speech,orig_sr=sample_rate, target_sr=16000)\n",
        "\n",
        "#Tokenize\n",
        "input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
        "#Take logits\n",
        "logits = model(input_values).logits\n",
        "#Take argmax\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "#Get the words from predicted word ids\n",
        "transcription = tokenizer.decode(predicted_ids[0])\n",
        "#Correcting the letter casing\n",
        "sentences = nltk.sent_tokenize(transcription.lower())\n",
        "transcription = (' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))\n",
        "#create dictionary\n",
        "d = {}\n",
        "d.update({\"task_1_output\": transcription})\n",
        "\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0EwDEazD-Ph",
        "outputId": "63da5498-57d4-44c0-c201-5dfb0fc2b087"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello i nancy this is like from eightient incorporation yes how can i help you nancy you have been using our preepa connection for a couple of years now right ye that's right how would you like a postpa connection that allows you to make free unlimited voice calls to three eightent numbers i would love that but what's the catch there's no catch there will be a monthly rental which you will have to pay like any other postpaid connection fantastic sign me up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the dataset\n",
        "data = pd.DataFrame({\n",
        "    'Text': [\n",
        "        \"My name is Jeff and I am calling from Amazon.\",\n",
        "        \"I am calling from Microsoft and my name is Satya.\",\n",
        "        \"I am Sundar and this is a call from Google.\",\n",
        "        \"I am calling about your Microsoft Azure subscription.\",\n",
        "        \"This is a call regarding your Google Cloud Platform account.\",\n",
        "        \"I would like to talk about your Amazon Web Services account.\",\n",
        "        \"Hello, this is John from IBM.\",\n",
        "        \"I'm calling on behalf of Apple.\",\n",
        "        \"My name is Emily, and I represent Tesla.\",\n",
        "        \"This call is related to your Salesforce subscription.\",\n",
        "        \"I'm reaching out about your Oracle database.\",\n",
        "        \"Good day, I am Tom calling from Facebook.\"\n",
        "    ],\n",
        "    'Label': ['Intro', 'Intro', 'Intro', 'Purpose', 'Purpose', 'Purpose', 'Intro',  'Intro', 'Intro','Purpose','Purpose','Intro']\n",
        "})\n",
        "\n",
        "X = data['Text']\n",
        "y = data['Label']\n",
        "\n",
        "#convert to vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X)\n",
        "#train model\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train_vec,y)\n",
        "\n",
        "txt = \"Hello. Hi Nancy. This is Mike from AT&T and Corporation for a couple of years now, right? That's right. I would you like a postpaid connection that allows you to make free unlimited voice calls to 38 e, n t numbers. I would love that, but what's the catch? There's no catch, there will be a monthly rental, which you will have to pay like any other postpaid connection. Fantastic sign me up. There's no catch, there will be a monthly rental, which you will have to pay like any other postpaid connection. Fantastic sign me up.\"\n",
        "All_text = txt.split(\".\")\n",
        "intent = []\n",
        "for sent in All_text:\n",
        "    new_text_vec = vectorizer.transform([sent])\n",
        "    predicted_category = model.predict(new_text_vec)\n",
        "    intent.append(predicted_category[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "MhLeR5gfvbMQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#blank english model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "#Define the entity\n",
        "entity_labels = [\"caller_name\", \"company\", \"product\"]\n",
        "\n",
        "#Add the entity recognizer\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "\n",
        "#Add the labels to the entity recognizer\n",
        "for label in entity_labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "#Prepare the dataset\n",
        "TRAIN_DATA = [\n",
        "    (\"My name is Jeff and I am calling from Amazon.\", {\"entities\": [(11, 15, \"caller_name\"), (38, 44, \"company\")]}),\n",
        "    (\"I am calling from Microsoft and my name is Satya.\", {\"entities\": [(19, 28, \"company\"), (45, 50, \"caller_name\")]}),\n",
        "    (\"I am Sundar and this is a call from Google.\", {\"entities\": [(5, 11, \"caller_name\"), (37, 43, \"company\")]}),\n",
        "    (\"I am calling about your Microsoft Azure subscription.\", {\"entities\": [(25, 41, \"product\")]}),\n",
        "    (\"This is a call regarding your Google Cloud Platform account.\", {\"entities\": [(32, 54, \"product\")]}),\n",
        "    (\"I would like to talk about your Amazon Web Services account.\", {\"entities\": [(33, 55, \"product\")]}),\n",
        "    (\"My name is Jeff and I am calling from Amazon.\", {\"entities\": [(11, 15, \"caller_name\"), (38, 44, \"company\")]}),\n",
        "    (\"I am calling from Microsoft and my name is Satya.\", {\"entities\": [(19, 28, \"company\"), (45, 50, \"caller_name\")]}),\n",
        "    (\"I am Sundar and this is a call from Google.\", {\"entities\": [(5, 11, \"caller_name\"), (37, 43, \"company\")]}),\n",
        "    (\"I am calling about your Microsoft Azure subscription.\", {\"entities\": [(25, 41, \"product\")]}),\n",
        "    (\"This is a call regarding your Google Cloud Platform account.\", {\"entities\": [(32, 54, \"product\")]}),\n",
        "    (\"I would like to talk about your Amazon Web Services account.\", {\"entities\": [(33, 55, \"product\")]}),\n",
        "    (\"My name is Jeff and I am calling from Amazon.\", {\"entities\": [(11, 15, \"caller_name\"), (38, 44, \"company\")]}),\n",
        "    (\"I am calling from Microsoft and my name is Satya.\", {\"entities\": [(19, 28, \"company\"), (45, 50, \"caller_name\")]}),\n",
        "    (\"I am Sundar and this is a call from Google.\", {\"entities\": [(5, 11, \"caller_name\"), (37, 43, \"company\")]}),\n",
        "    (\"I am calling about your Microsoft Azure subscription.\", {\"entities\": [(25, 41, \"product\")]}),\n",
        "    (\"This is a call regarding your Google Cloud Platform account.\", {\"entities\": [(32, 54, \"product\")]}),\n",
        "    (\"I would like to talk about your Amazon Web Services account.\", {\"entities\": [(33, 55, \"product\")]}),\n",
        "    (\"My name is John from IBM. I want to discuss Azure.\", {\"entities\": [(11, 15, \"caller_name\"), (20, 23, \"company\"), (42, 47, \"product\")]}),\n",
        "    (\"Hello, this is Emily calling about Microsoft Office. I'm from Salesforce.\", {\"entities\": [(20, 25, \"caller_name\"), (42, 57, \"product\"), (66, 75, \"company\")]}),\n",
        "    (\"I'm Alex and I represent Tesla. Let's talk about Google Cloud Platform.\", {\"entities\": [(4, 8, \"caller_name\"), (23, 28, \"company\"), (52, 73, \"product\")]}),\n",
        "    (\"My name is Sarah from Oracle. I want to discuss Amazon Web Services.\", {\"entities\": [(11, 16, \"caller_name\"), (21, 27, \"company\"), (47, 67, \"product\")]}),\n",
        "    (\"Hello, this is Michael calling about IBM Watson. I'm from Facebook.\", {\"entities\": [(20, 27, \"caller_name\"), (42, 52, \"product\"), (59, 66, \"company\")]}),\n",
        "    (\"I'm Olivia and I represent Apple. Let's talk about Microsoft Office.\", {\"entities\": [(4, 10, \"caller_name\"), (27, 32, \"company\"), (51, 66, \"product\")]}),\n",
        "    (\"My name is John from Tesla. I want to discuss Amazon Web Services.\", {\"entities\": [(11, 15, \"caller_name\"), (20, 25, \"company\"), (42, 62, \"product\")]}),\n",
        "    (\"Hello, this is Emily calling about Azure. I'm from Salesforce.\", {\"entities\": [(20, 25, \"caller_name\"), (42, 47, \"product\"), (61, 70, \"company\")]}),\n",
        "    (\"I'm Alex and I represent IBM. Let's talk about Google Cloud Platform.\", {\"entities\": [(4, 8, \"caller_name\"), (23, 26, \"company\"), (50, 71, \"product\")]}),\n",
        "    (\"My name is Sarah from Microsoft Office. I want to discuss Oracle.\", {\"entities\": [(11, 16, \"caller_name\"), (21, 36, \"company\"), (50, 56, \"product\")]}),\n",
        "    (\"Hello, this is Michael calling about Amazon Web Services. I'm from Facebook.\", {\"entities\": [(20, 27, \"caller_name\"), (42, 62, \"product\"), (69, 76, \"company\")]}),\n",
        "    (\"I'm Olivia and I represent Google Cloud Platform. Let's talk about IBM Watson.\", {\"entities\": [(4, 10, \"caller_name\"), (27, 48, \"company\"), (63, 74, \"product\")]}),\n",
        "    (\"My name is John from Amazon Web Services. I want to discuss Salesforce.\", {\"entities\": [(11, 15, \"caller_name\"), (20, 40, \"company\"), (49, 58, \"product\")]}),\n",
        "    (\"Hello, this is Emily calling about Oracle. I'm from Tesla.\", {\"entities\": [(20, 25, \"caller_name\"), (42, 48, \"product\"), (59, 64, \"company\")]})\n",
        "]\n",
        "\n",
        "# Disable unnecessary pipeline\n",
        "disable_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "# Train the model\n",
        "with nlp.disable_pipes(*disable_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for epoch in range(10):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for text, annotations in TRAIN_DATA:\n",
        "            doc = nlp.make_doc(text)\n",
        "            example = Example.from_dict(doc, annotations)\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(\"Epoch:\", epoch, \"Losses:\", losses)\n",
        "nlp.to_disk(\"/content/trained_model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bcnHAo87owd",
        "outputId": "de1de8fc-8ab3-486c-d103-1d92595bd1cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I am Sundar and this is a call from Google.\" with entities \"[(5, 11, 'caller_name'), (37, 43, 'company')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hello, this is Michael calling about Amazon Web Se...\" with entities \"[(20, 27, 'caller_name'), (42, 62, 'product'), (69...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I'm Olivia and I represent Apple. Let's talk about...\" with entities \"[(4, 10, 'caller_name'), (27, 32, 'company'), (51,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I am calling from Microsoft and my name is Satya.\" with entities \"[(19, 28, 'company'), (45, 50, 'caller_name')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I am calling about your Microsoft Azure subscripti...\" with entities \"[(25, 41, 'product')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"My name is John from IBM. I want to discuss Azure.\" with entities \"[(11, 15, 'caller_name'), (20, 23, 'company'), (42...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"This is a call regarding your Google Cloud Platfor...\" with entities \"[(32, 54, 'product')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I would like to talk about your Amazon Web Service...\" with entities \"[(33, 55, 'product')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"My name is Sarah from Microsoft Office. I want to ...\" with entities \"[(11, 16, 'caller_name'), (21, 36, 'company'), (50...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"My name is John from Amazon Web Services. I want t...\" with entities \"[(11, 15, 'caller_name'), (20, 40, 'company'), (49...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hello, this is Michael calling about IBM Watson. I...\" with entities \"[(20, 27, 'caller_name'), (42, 52, 'product'), (59...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hello, this is Emily calling about Microsoft Offic...\" with entities \"[(20, 25, 'caller_name'), (42, 57, 'product'), (66...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I'm Olivia and I represent Google Cloud Platform. ...\" with entities \"[(4, 10, 'caller_name'), (27, 48, 'company'), (63,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hello, this is Emily calling about Oracle. I'm fro...\" with entities \"[(20, 25, 'caller_name'), (42, 48, 'product'), (59...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"My name is Sarah from Oracle. I want to discuss Am...\" with entities \"[(11, 16, 'caller_name'), (21, 27, 'company'), (47...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I'm Alex and I represent IBM. Let's talk about Goo...\" with entities \"[(4, 8, 'caller_name'), (23, 26, 'company'), (50, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"My name is John from Tesla. I want to discuss Amaz...\" with entities \"[(11, 15, 'caller_name'), (20, 25, 'company'), (42...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I'm Alex and I represent Tesla. Let's talk about G...\" with entities \"[(4, 8, 'caller_name'), (23, 28, 'company'), (52, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hello, this is Emily calling about Azure. I'm from...\" with entities \"[(20, 25, 'caller_name'), (42, 47, 'product'), (61...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Losses: {'ner': 92.25466343276847}\n",
            "Epoch: 1 Losses: {'ner': 7.668230379147374}\n",
            "Epoch: 2 Losses: {'ner': 4.628165412485447}\n",
            "Epoch: 3 Losses: {'ner': 1.6646014207981776}\n",
            "Epoch: 4 Losses: {'ner': 1.9652608956701454}\n",
            "Epoch: 5 Losses: {'ner': 0.9706916448377712}\n",
            "Epoch: 6 Losses: {'ner': 1.2550992650463648}\n",
            "Epoch: 7 Losses: {'ner': 1.9750809606560018}\n",
            "Epoch: 8 Losses: {'ner': 15.781432280974267}\n",
            "Epoch: 9 Losses: {'ner': 1.092679572403554}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the input text\n",
        "nlp = spacy.load(\"/content/trained_model\")\n",
        "d.update({\"task_3_output\":[]})\n",
        "i=0\n",
        "#Find entities\n",
        "for sent in All_text:\n",
        "    d[\"task_3_output\"].append({\"sentence\":sent, \"intent\":intent[i],\"entities\": []})\n",
        "    i = i+1\n",
        "    doc = nlp(sent)\n",
        "    for ent in doc.ents:\n",
        "        d[\"task_3_output\"][i-1][\"entities\"].append({\"entity_name\": ent.text,\"entity_value\": ent.label_})"
      ],
      "metadata": {
        "id": "1DIK8Unj76px"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_object = json.dumps(d, indent=4)\n",
        "#Save json\n",
        "with open(\"/content/data.json\", \"w\") as f:\n",
        "    json.dump(json_object,f)"
      ],
      "metadata": {
        "id": "rLYJNjU5HjGN"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}